{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      },
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 018\n",
        "Code Title: | Emerging Technologies in CpE 1 - Fundamentals of Computer Vision\n",
        "1st Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "<u>**ACTIVITY NO.** | **TITLE**\n",
        "**Name** | Malaki, Karl Josef\n",
        "**Section** | CPE32s3\n",
        "**Date Performed**: |Feb 21,2025\n",
        "**Date Submitted**: |Feb 21, 2025\n",
        "**Instructor**: | Dr. Jonathan V. Taylar / Engr. Verlyn V. Nojor / Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMxAUPJGYLw"
      },
      "source": [
        "## 1. Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0bUEs1nxE0"
      },
      "source": [
        "This activity aims to allow students to perform face detection on still images and videos using Haar cascades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-8nSpXFpyd"
      },
      "source": [
        "## 2. Intended Learning Outcomes (ILOs)\n",
        "After this activity, the students should be able to:\n",
        "* Utilize OpenCV to detect faces in still images and videos.\n",
        "* Demonstrate the use of Haar-like features for detection of other human features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-RNZovNGV9k"
      },
      "source": [
        "## 3. Procedures and Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NzR4JDbiyDg"
      },
      "source": [
        "Contrary to initial assumptions, conducting face detection on a static image and a video stream shares a remarkable similarity. Essentially, the latter is merely a sequential rendition of the former: when detecting faces in videos, it essentially involves applying face detection to every individual frame obtained from the camera feed. Of course, video face detection introduces additional elements like tracking, which aren't relevant to static images. Nevertheless, it's valuable to recognize that the fundamental principles behind both processes remain consistent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1gC-lR2izhw"
      },
      "source": [
        "### Performing face detection on still image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMLyshf2izdI"
      },
      "source": [
        "The first and most basic way to perform face detection is to load an image and detect faces in it. To make the result visually meaningful, we will draw rectangles around faces on the original image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkwbbeEAoPlw"
      },
      "source": [
        "**Before implementing the code below**, check the contents of the `cv2.CascadeClassifier()` function. Provide an explanation of the function, its parameters before running the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/9f/6e/264673e64001b99d747aff5a288eca82826c024437a3694e19aed1decf46/matplotlib-3.10.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/a1/35/c2de8823211d07e8a79ab018ef03960716c5dff6f4d5bff5af87fd682992/contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata\n",
            "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/6f/e3/5a181a85777f7809076e51f7422e0dc77eb04676c40ec8bf6a49d390d1ff/fonttools-4.56.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl.metadata (103 kB)\n",
            "     ---------------------------------------- 0.0/104.0 kB ? eta -:--:--\n",
            "     -------------------------------------- 104.0/104.0 kB 5.9 MB/s eta 0:00:00\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/bd/72/dfff0cc97f2a0776e1c9eb5bef1ddfd45f46246c6533b0191887a427bca5/kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata\n",
            "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\karl josef malaki\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\karl josef malaki\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.0)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Obtaining dependency information for pillow>=8 from https://files.pythonhosted.org/packages/08/5c/2104299949b9d504baf3f4d35f73dbd14ef31bbd1ddc2c1b66a5b7dfda44/pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata\n",
            "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/1c/a7/c8a2d361bf89c0d9577c934ebb7421b25dc84bf3a8e3ac0a40aed9acc547/pyparsing-3.2.1-py3-none-any.whl.metadata\n",
            "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\karl josef malaki\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\karl josef malaki\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
            "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.5/8.0 MB 15.5 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 1.3/8.0 MB 16.0 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 2.0/8.0 MB 15.9 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 2.8/8.0 MB 16.5 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 3.5/8.0 MB 16.1 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 4.3/8.0 MB 16.0 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 4.8/8.0 MB 15.4 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 5.1/8.0 MB 14.9 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 5.7/8.0 MB 14.0 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 6.1/8.0 MB 13.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 6.6/8.0 MB 13.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 7.2/8.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  7.9/8.0 MB 13.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.0/8.0 MB 12.8 MB/s eta 0:00:00\n",
            "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
            "   ---------------------------------------- 0.0/221.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 221.0/221.0 kB 4.5 MB/s eta 0:00:00\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ------------ --------------------------- 0.7/2.2 MB 13.9 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.3/2.2 MB 13.3 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 1.9/2.2 MB 13.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 12.7 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
            "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 71.9/71.9 kB 3.9 MB/s eta 0:00:00\n",
            "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
            "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
            "   ------- -------------------------------- 0.5/2.6 MB 14.7 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 1.0/2.6 MB 11.0 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 1.6/2.6 MB 11.3 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 2.0/2.6 MB 10.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.5/2.6 MB 11.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.6/2.6 MB 10.5 MB/s eta 0:00:00\n",
            "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "   ---------------------------------------- 0.0/107.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 107.7/107.7 kB 6.1 MB/s eta 0:00:00\n",
            "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c4TmUw_BEeUc"
      },
      "outputs": [],
      "source": [
        "# Make sure that for this activity, you have downloaded the\n",
        "# file indicated below from the resource linked in the instructional materials\n",
        "# in the module.\n",
        "\n",
        "import cv2\n",
        "\n",
        "picPath = 'breaking_bad.jpg'\n",
        "haarPath = 'haarcascade_frontalface_default.xml'\n",
        "\n",
        "def faceDetect(picPath):\n",
        "  face_cascade = cv2.CascadeClassifier(haarPath)\n",
        "\n",
        "  img = cv2.imread(picPath)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "  for (x, y, w, h) in faces:\n",
        "    img = cv2.rectangle(img, (x, y), (x+w, y+h), (255,0,0), 2)\n",
        "\n",
        "  cv2.imshow('breaking_bad',img)\n",
        "  cv2.waitKey(0)\n",
        "  cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "iMDiBHDHn0qw",
        "outputId": "0cd87035-318d-46d6-c107-8e83ef046228"
      },
      "outputs": [],
      "source": [
        "faceDetect(picPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QKfV7ANos6O"
      },
      "source": [
        "**Analysis**:\n",
        "- Based on your earlier analysis, where do you think the face detection works in the line of code above?\n",
        "- Provide an analysis of the parameters of the `detectMultiScale` method.\n",
        "- Change the color of the border of the detected faces to red.\n",
        "- Are you able to make the borders thicker? Demonstrate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwmnM14FcF8M"
      },
      "source": [
        "***INTERPRETATION***\n",
        "- The face detection part is in the Cascade Classifier where it uses the haarpath and also the detectMultiscale.\n",
        "\n",
        "- Detectmultiscale scans the image for faces using the cascade classifier. If it sees a face it uses a list of rectangles that shows were the faces are\n",
        "\n",
        "- To change the color of the rectangle i have to change the tuple (255,0,0) found in the parameter of the rectangle function\n",
        "\n",
        "- To change the size of the rectangle, i have to change the integer found beside the color tuple (currently number 2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yap3yT5PsO8Q"
      },
      "source": [
        "### Performing face detection on video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZbxG6gBphzF"
      },
      "source": [
        "**Step 1**: Create a file called face_detection.py and include the following codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tBVolHTcGoCo"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WboZyA6lpk81"
      },
      "source": [
        "**Step 2:** After this, we declare a method, `detect()`, which will perform face detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RHorhmfopnvV"
      },
      "outputs": [],
      "source": [
        "def detect():\n",
        "  face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
        "  eye_cascade = cv2.CascadeClassifier('/content/haarcascade_eye.xml')\n",
        "  camera = cv2.VideoCapture(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W4p9q1OqYP0"
      },
      "source": [
        "**Step 3:** The first thing we need to do inside the detect() method is to load the Haar cascade files so that OpenCV can operate face detection. As we copied\n",
        "the cascade files in the local `cascades/` folder, we can use a relative path. Then, we open a VideoCapture object (the camera feed). The VideoCapture  constructor takes a parameter, which indicates the camera to be used; zero indicates the first camera available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "3vVGMXB7rjPT",
        "outputId": "0a68d280-fc3c-4173-bb4a-82eabaafec70"
      },
      "outputs": [],
      "source": [
        "  while (True):\n",
        "    ret, frame = camera.read()\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zieVeRN_rlxa"
      },
      "source": [
        "**Step 4:** Next up, we capture a frame. The read() method returns two values: a Boolean indicating the success of the frame read operation, and the frame\n",
        "itself. We capture the frame, and then we convert it to grayscale. This is a necessary operation, because face detection in OpenCV happens in the grayscale color space:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_LBk8P-r36S"
      },
      "outputs": [],
      "source": [
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K3VPUQRr7ii"
      },
      "source": [
        "**Step 5:** Much like the single still image example, we call detectMultiScale on the grayscale version of the frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELwHm8NqsAIp"
      },
      "outputs": [],
      "source": [
        "  for (x,y,w,h) in faces:\n",
        "    img = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray, 1.03,\n",
        "    5, 0, (40,40))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MA68hKlse7I"
      },
      "source": [
        "**Step 6:** Here we have a further step compared to the still image example: we create a region of interest corresponding to the face rectangle, and within this rectangle, we operate \"eye detection\". This makes sense as you wouldn't want to go looking for eyes outside a face (well, for human beings at least!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9V5PPcfsjpX"
      },
      "outputs": [],
      "source": [
        "  for (ex,ey,ew,eh) in eyes:\n",
        "    cv2.rectangle(img,(ex,ey),(ex+ew,ey+eh),\n",
        "    (0,255,0),2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzqjveHPspQ3"
      },
      "source": [
        "**Step 7:** Again, we loop through the resulting eye tuples and draw green rectangles around them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJlmIIERso0w"
      },
      "outputs": [],
      "source": [
        "\n",
        "    cv2.imshow(\"camera\", frame)\n",
        "    if cv2.waitKey(1000 / 12) & 0xff == ord(\"q\"):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "detect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "def detect():\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "  eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "  camera = cv2.VideoCapture(0)\n",
        "\n",
        "  while True:\n",
        "    ret, frame = camera.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "      cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "      roi_gray = gray[y:y+h, x:x+w]\n",
        "      roi_color = frame[y:y+h, x:x+w]\n",
        "      eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "      for (ex, ey, ew, eh) in eyes:\n",
        "        cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imshow('Face and Eye Detection', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "detect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI59-kERsyxP"
      },
      "source": [
        "**Provide the following**:\n",
        "- Screenshot of the output for the working code once you've put it all together.\n",
        "- Summary of the steps you've performed along with observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkyd0KjtGl79"
      },
      "source": [
        "## 4. Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLjTzJoxpT-N"
      },
      "source": [
        "In your Cameo project, include real-time face detection using Haar cascade. Show screenshots of the working demonstration for this supplementary activity.\n",
        "\n",
        "Additionally, implement similar steps to detect a smile using Haar cascades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def detect():\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "  eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "  smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
        "  camera = cv2.VideoCapture(0)\n",
        "\n",
        "  while True:\n",
        "    ret, frame = camera.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "      cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "      roi_gray = gray[y:y+h, x:x+w]\n",
        "      roi_color = frame[y:y+h, x:x+w]\n",
        "      \n",
        "      eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "      for (ex, ey, ew, eh) in eyes:\n",
        "        cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
        "      \n",
        "      smiles = smile_cascade.detectMultiScale(roi_gray, 1.8, 20)\n",
        "      for (sx, sy, sw, sh) in smiles:\n",
        "        cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (0, 255, 255), 2)\n",
        "\n",
        "    cv2.imshow('Face, Eye, and Smile Detection', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "detect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspxP0IGoO1"
      },
      "source": [
        "## 5. Summary, Conclusions and Lessons Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvcmGICAoj1a"
      },
      "source": [
        "For activity 6, I was tasked to create a face,smile and eye detection using haarcascade.xml files. This one is actually quite easy to understand, you basically just create a detect() function and use the MultiScale function then display it in the window. Other than that, it is also quite easy because I pretty much reused the code above and tweaked it a little by adding the eyes and the smile part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlVIPSqolAC"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "***Proprietary Clause***\n",
        "\n",
        "*Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ElMxAUPJGYLw",
        "X-RNZovNGV9k",
        "Mkyd0KjtGl79",
        "KQspxP0IGoO1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
